{"index":{"title":"Karan Singh","links":["assets/lp-notes.pdf"],"tags":[],"content":"\nemail: firstnamelastname@cmu.edu\n\n\nHello, there ðŸ‘‹. My name is Karan Singh.\nI am an Assistant Professor of Operations Research at the Tepper School of Business at Carnegie Mellon University. I study the algorithmic aspects of machine learning. Iâ€™m especially interested in interactive learning paradigms, like reinforcement learning. My research both borrows techniques from and synthesizes tools in online learning, mathematical optimization, statistics and control theory. Some of my recent research topics:\n\nAlgorithmic Reductions: Can one efficiently solve hard learning problems (e.g., reinforcement learning) given blackbox solvers for well-understood, easier ones (e.g., weak classifiers)? Are such algorithmic reductions sample-efficient? We answer such these to give efficient algorithms for online boosting, boosting for RL, and RL with concave rewards.\nNonstochastic Control paves an algorithmic, against a traditionally analytic, foundation for control theory. We give provably efficient instance-optimal control algorithms. By extending online learning to stateful systems and establishing low-regret guarantees, these go beyond both average-case notions of optimal control and worst-case notions in robust control.\nPrivacy and Online Learning: Online convex optimization provides robust, yet performant, algorithms for learning and online decision-making. What is the best achievable regret for OCO under privacy constraints? This links to an older question on steadfastness in online learning, and we give the first results which match the best obtainable in non-private settings.\n\nI completed my PhD in Computer Science at Princeton University, advised by Elad Hazan. Following this, I was a postdoc at Microsoft Research in Redmond. Long ago, I was an Computer Science undergrad at Indian Institute of Technology (IIT) Kanpur.\n\n\n                  \n                  Draft of a new text on \n                  \n                \nIntroduction to Online Nonstochastic Control with Elad Hazan\n\nPublications\nImproved Differentially Private and Lazy Online Convex Optimization: Lower Regret without Smoothness Requirements\nwith Naman Agarwal, Sayten Kale and Abhradeep Thakurta\nInternational Conference on Machine Learning (ICML), 2024\nproceedings soon | arXiv\nOnline Nonstochastic Model-Free Reinforcement Learning\nwith Udaya Ghai, Arushi Gupta, Wenhan Xia and Elad Hazan\nNeural Information Processing Systems (NeurIPS), 2023\nproceedings | arXiv\nDifferentially Private and Lazy Online Convex Optimization\nwith Naman Agarwal, Sayten Kale and Abhradeep Thakurta\nConference on Learning Theory (COLT), 2023\nproceedings | arXiv soon\nBest of Both Worlds in Online Control: Competitive Ratio and Policy Regret\nwith Gautam Goel, Naman Agarwal and Elad Hazan\nLearning for Dynamics and Control (L4DC), 2023\nproceedings | arXiv\nVariance-reduced Conservative Policy Iteration\nwith Naman Agarwal and Brian Bullins\nAlgorithmic Learning Theory (ALT), 2023\nproceedings | arXiv\nA Boosting Approach to Reinforcement Learning\nwith Nataly Brukhim and Elad Hazan\nNeural Information Processing Systems (NeurIPS), 2022\nproceedings | arXiv\nBoosting for Online Convex Optimization\nwith Elad Hazan\nInternational Conference on Machine Learning (ICML), 2021\nproceedings | arXiv\nA Regret Minimization Approach to Iterative Learning Control\nwith Naman Agarwal, Elad Hazan, Anirudha Majumdar\nInternational Conference on Machine Learning (ICML), 2021\nproceedings | arXiv\nImproper Learning for Nonstochastic Control\nwith Max Simchowitz, Elad Hazan\nConference on Learning Theory (COLT), 2020\nproceedings | arXiv\nNo-Regret Prediction in Marginally Stable Systems\nwith Udaya Ghai, Holden Lee, Cyril Zhang, Yi Zhang\nConference on Learning Theory (COLT), 2020\nproceedings | arXiv\nThe Nonstochastic Control Problem\nwith Elad Hazan, Sham Kakade\nAlgorithmic Learning Theory (ALT), 2020\nproceedings | arXiv\nLogarithmic Regret for Online Control\nwith Naman Agarwal, Elad Hazan\nNeural Information Processing Systems (NeurIPS), 2019 Oral Presentation (&lt;0.5% of submissions)\nAlso, Best Paper Award at the OptRL workshop at NeurIPS 2019\nproceedings | arXiv\nOnline Control with Adversarial Disturbances\nwith Naman Agarwal, Brian Bullins, Elad Hazan, Sham Kakade\nInternational Conference on Machine Learning (ICML), 2019\nproceedings | arXiv\nProvably Efficient Maximum Entropy Exploration\nwith Elad Hazan, Sham Kakade, Abby Van Soest\nInternational Conference on Machine Learning (ICML), 2019\nproceedings | arXiv\nEfficient Full-Matrix Adaptive Regularization\nwith Naman Agarwal, Brian Bullins, Xinyi Chen, Elad Hazan, Cyril Zhang, Yi Zhang\nInternational Conference on Machine Learning (ICML), 2019\nproceedings | arXiv\nSpectral Filtering for General Linear Dynamical Systems\nwith Elad Hazan, Holden Lee, Cyril Zhang, Yi Zhang\nNeural Information Processing Systems (NeurIPS), 2018 Oral Presentation (&lt;0.5% of submissions)\nproceedings | arXiv\nLearning Linear Dynamical Systems via Spectral Filtering\nwith Elad Hazan, Cyril Zhang\nNeural Information Processing Systems (NeurIPS), 2017 Spotlight (&lt;5% of submissions)\nAlso, Spotlight Prize at New York Academy of Sciencesâ€™ ML Symposium, 2018\nproceedings | arXiv\nThe Price of Differential Privacy for Online Learning\nwith Naman Agarwal\nInternational Conference on Machine Learning (ICML), 2017\nproceedings | arXiv\nEfficient Regret Minimization in Non-Convex Games\nwith Elad Hazan, Cyril Zhang\nInternational Conference on Machine Learning (ICML), 2017\nproceedings | arXiv\nTechnical Reports\nDynamic Learning System\nwith Elad Hazan, Cyril Zhang\nUS Patent 11,138,513 B2, approved Oct 2021\nMachine Learning for Mechanical Ventilation Control\nwith Daniel Suo, Cyril Zhang, Paula Gradu, Udaya Ghai, Xinyi Chen, Edgar Minasyan, Naman Agarwal, Julienne LaChance, Tom Zajdel, Manuel Schottdorf, Daniel Cohen, Elad Hazan\nMachine Learning for Health (ML4H), 2021 Workshop Track\nFeatured in Princeton Engineering news.\nDeluca â€” A Differentiable Control Library: Environments, Methods, and Benchmarking\nwith Paula Gradu, John Hallman, Daniel Suo, Alex Yu, Naman Agarwal, Udaya Ghai, Cyril Zhang, Anirudha Majumdar, Elad Hazan\nNeurIPS Workshop on Differentiable Computer Vision &amp; Physics, 2020 Oral Presentation\nTowards Provable Control for Unknown Linear Dynamical Systems\nwith Sanjeev Arora, Elad Hazan, Holden Lee, Cyril Zhang, Yi Zhang\nInternational Conference on Learning Representation (ICLR), 2018 Workshop Track\nDynamic Task Allocation for Crowdsourcing\nwith Irineo Cabreros, Angela Zhou\nICML Workshop on Data Efficient Machine Learning, 2016\nLecture Notes\nLinear Programming Fall 2023\nLess simplex, more geometry and regret minimization. Algorithmic proofs."},"notes/rg":{"title":"Generative Models for Optimization","links":[],"tags":[],"content":"Generative Models for Optimization\nWith Macarena &amp; Willem.\n\\int f d\\mu = f_\\mu "}}