<!DOCTYPE html>
<!-- saved from url=(0074)file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/index.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
  <link rel="stylesheet" type="text/css" href="./Karan Singh_files/style.css">
  <link rel="icon" type="image/png" href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/images/pu.png">
  <title>Karan Singh</title>
  <script src="./Karan Singh_files/scramble.js.download"></script>
</head>

<body>
  <table cellspacing="0" cellpadding="0" border="0" width="800" align="center">
    <tbody>
      <tr>
        <td>
          <table cellspacing="0" cellpadding="10" border="0" width="80%" align="center">
            <tbody>
              <tr bgcolor="#ffffff">
                <td width="100%" valign="middle" style="padding-left: 0px;">
                  <p align="center">
                    <name>Karan Singh</name><br>
                    <b>email</b>:
                    <font id="covermail">
                      <font id="email" style="display:inline;">.@alammirhnaciinomkgags <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/index.html#" onclick="emailScramble.initAnimatedBubbleSort();return false;">unscramble</a></font>
                    </font>
                    <script>
                      emailScramble = new scrambledString(document.getElementById('email'),
                        'emailScramble', 'karansingh@iamgmail.com',
                        [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1, 2, 3, 15, 16, 17, 18, 19, 20, 21, 22, 23]);
                      function unscram() {
                        emailScramble.initAnimatedBubbleSort();
                        var elem = document.getElementById('covermail');
                        elem.style.backgroundColor = 'yellow';
                      }
                    </script>
                  </p>
                  <p>
                    Karan Singh is a postdoctoral researcher at <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a> in the <a href="https://www.microsoft.com/en-us/research/theme/reinforcement-learning-group/">Reinforcement
                      Learning</a> group.
                    In Novemeber 2021, he completed his PhD in <a href="http://cs.princeton.edu/">Computer Science</a> at
                    <a href="http://www.princeton.edu/">Princeton University</a>, advised by <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>. While at Princeton, Karan was awarded the
                    Porter Ogden Jacobus Fellowship (<a href="https://www.princeton.edu/news/2020/02/13/four-win-jacobus-fellowship-princetons-top-graduate-student-honor">press</a>,
                    <a href="https://www.dailyprincetonian.com/article/2020/02/four-graduate-students-named-jacobus-fellows">more</a>),
                    Princeton University's highest graduate student honor. Before that, he completed his bachelors at <a href="http://iitk.ac.in/">Indian Institute of Technology (IIT) Kanpur</a>, where he received the
                    President's Gold Medal (<a href="https://timesofindia.indiatimes.com/director-iit-k-prof-indranil-manna-informed-that-while-the-presidents-gold-medal-will-be-given-to-karan-singh-of-computer-science-and-engineering-department-directors-gold-medal-will-be-awarded-to-sarthak-chandra-of-physics-department-/articleshow/47568494.cms">press</a>)
                    for the best academic performance in the graduating class.
                  </p>
                  <p>
                    Karan's research is focussed on provably efficient
                    efficient <strong>robust</strong> algorithms for <strong> control</strong> and <strong>reinforcement
                      learning</strong>, aided by the lens of <strong>dynamical systems</strong> and the algorithmic
                    toolkit of <strong>optimization</strong> and (non-stochastic) <strong>online learning</strong>.
                  </p>
                  <p align="center">
                    <a onclick="unscram();">Email</a> &nbsp;|&nbsp;
                    <a href="https://i-am-karan-singh.github.io/docs/cv/KaranSingh-Resume.pdf">CV</a> &nbsp;|&nbsp;
                    <a href="https://scholar.google.com/citations?user=PZJIgZUAAAAJ&amp;hl=en">Google Scholar</a>
                  </p>
                </td>
                <td width="0%">
                  <img width="150" src="./Karan Singh_files/karan.gif">
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="00">
            <tbody><tr>
              <td>
                <heading>News</heading>
                <ul>
                  <li> <i>[November 2021]</i> Karan is on the <strong>academic job market for 2021-22</strong>.</li>
                  <li> <i>[July 2021]</i> Tutorial with <a href="https://www.ehazan.com/">Elad Hazan</a> on <a href="https://sites.google.com/view/nsc-tutorial/home">Nonstochastic Control</a> at <a href="https://icml.cc/Conferences/2021">ICML 2021</a>. (<strong><a href="https://icml.cc/virtual/2021/tutorial/10838">recordings</a></strong>)</li>
                  <li> <i>[May 2021]</i> <a href="https://proceedings.mlr.press/v139/agarwal21b.html">Two</a> <a href="https://proceedings.mlr.press/v139/hazan21a.html">papers</a> accepted at <a href="https://icml.cc/Conferences/2021">ICML 2021</a>.</li>
                  <li> <i>[January 2021]</i> Joint <a href="https://arxiv.org/abs/2102.06779">work</a> on ML for
                    Mechanical Ventilation was featured in <a href="https://engineering.princeton.edu/news/2021/01/26/engineering-and-artificial-intelligence-combine-safeguard-patients-lives">Princeton
                      Engineering news</a>.</li>
                </ul>
              </td>
            </tr>
          </tbody></table>

          <table cellspacing="0" cellpadding="00" border="0" width="100%" align="center">
            <tbody>
              <tr>
                <td width="100%" valign="middle">
                  <heading>Publications</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- <img src="images/new.png" height="15"> -->
          <table cellspacing="0" cellpadding="7" border="0" width="100%" align="center">
            <tbody>
              <tr>
                <td valign="top">
                  <a href="https://papers.nips.cc/paper/2019/file/78719f11fa2df9917de3110133506521-Paper.pdf" name="log-c">
                    <papertitle>Logarithmic Regret for Online Control
                    </papertitle>
                  </a><br>
                  with <a href="http://cs.princeton.edu/~namana/">Naman Agarwal</a>, <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a><br>
                  <em>Neural Information Processing Systems (NeurIPS)</em>, 2019 <strong>Oral Presentation</strong>
                  (&lt;0.5% of submissions) <br>
                  <a href="https://papers.nips.cc/paper/2019/file/78719f11fa2df9917de3110133506521-Paper.pdf">proceedings</a>
                  | <a href="https://arxiv.org/abs/1909.05062">arXiv</a>
                </td>
              </tr>
              <tr>
                <td width="100%" valign="top">
                  <p><a href="https://arxiv.org/abs/1911.12178" name="nsc">
                      <papertitle><img src="./Karan Singh_files/new.png" height="15">The Nonstochastic Control Problem</papertitle>
                    </a><br>
                    with <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>, <a href="https://homes.cs.washington.edu/~sham/">Sham Kakade</a><br>
                    <em>Algorithmic Learning Theory (ALT)</em>, 2020<br>
                    <a href="https://arxiv.org/abs/1911.12178">pdf</a> | <a href="https://arxiv.org/abs/1909.05062">arXiv</a>
                  </p><p></p>
                  <p>We consider the problem of controlling an unknown linear dynamical system with nonstochastic
                    adversarial perturbations and adversarial convex loss functions. The possibility of achieving
                    sub-linear regret was previously posed as an open question. We give an efficient algorithm that
                    achieves $T^{\frac{2}{3}}$ in this setting. Crucial to our result is a simple system
                    identification procedure that is effective under adversarial noise. </p>
                </td>
              </tr>
              <tr>
                <td width="25%" valign="middle">
                  <img width="200" src="./Karan Singh_files/h-inf.gif">
                </td>
                <td width="75%" valign="top">
                  <p><a href="http://proceedings.mlr.press/v97/agarwal19c/agarwal19c.pdf" name="h-inf">
                      <papertitle>Online Control with Adversarial Disturbances</papertitle>
                    </a><br>
                    with <a href="http://cs.princeton.edu/~namana/">Naman Agarwal</a>, <a href="https://www.cs.princeton.edu/~bbullins/">Brian Bullins</a>, <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>, <a href="https://homes.cs.washington.edu/~sham/">Sham Kakade</a><br>
                    <em>International Conference on Machine Learning (ICML)</em>, 2019 <br>
                    <a href="http://proceedings.mlr.press/v97/agarwal19c/agarwal19c.pdf">pdf</a> | <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/docs/h-inf/cite.bib">bibtex</a> | <a href="https://arxiv.org/abs/1902.08721">arXiv</a>
                  </p>
                  <p></p>
                  <p>We study the control of linear dynamical systems with adversarial disturbances, as opposed to
                    statistical noise. We present an efficient algorithm that achieves nearly-tight regret bounds in
                    this setting. Our result generalizes upon previous work in two main aspects: the algorithm can
                    accommodate adversarial noise in the dynamics, and can handle general convex costs.</p>
                </td>
              </tr>
              <tr>
                <td width="25%" valign="middle">
                  <img width="220" src="./Karan Singh_files/max-ent.gif">
                </td>
                <td width="75%" valign="top">
                  <p><a href="http://proceedings.mlr.press/v97/hazan19a/hazan19a.pdf" name="max-ent">
                      <papertitle>Provably Efficient Maximum Entropy Exploration</papertitle>
                    </a><br>
                    with <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>, <a href="https://homes.cs.washington.edu/~sham/">Sham Kakade</a>, <a href="http://www.abbyvansoest.com/">Abby Van Soest</a> <br>
                    <em>International Conference on Machine Learning (ICML)</em>, 2019 <br>
                    <a href="http://proceedings.mlr.press/v97/hazan19a/hazan19a.pdf">pdf</a> | <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/docs/max-ent/cite.bib">bibtex</a> | <a href="https://arxiv.org/abs/1812.02690">arXiv</a>
                  </p>
                  <p></p>
                  <p>Suppose an agent is in a (possibly unknown) Markov Decision Process in the absence of a reward
                    signal, what might we hope that an agent can efficiently learn to do? This work studies a broad
                    class of objectives that are defined solely as functions of the state-visitation frequencies that
                    are induced by how the agent behaves. For example, one natural, intrinsically defined, objective
                    problem is for the agent to learn a policy which induces a distribution over state space that is
                    as uniform as possible. We provide an efficient algorithm to optimize such such intrinsically
                    defined objectives, when given access to a black box planning oracle.</p>
                </td>
              </tr>
              <tr>
                <td width="25%" valign="middle">
                  <img width="220" height="170" src="./Karan Singh_files/ggt.PNG">
                </td>
                <td width="75%" valign="top">
                  <p><a href="http://proceedings.mlr.press/v97/agarwal19b/agarwal19b.pdf" name="ggt">
                      <papertitle>Efficient Full-Matrix Adaptive Regularization</papertitle>
                    </a><br>
                    with <a href="http://cs.princeton.edu/~namana/">Naman Agarwal</a>, <a href="https://www.cs.princeton.edu/~bbullins/">Brian Bullins</a>, <a href="https://xinyi.github.io/">Xinyi Chen</a>, <a href="http://cs.princeton.edu/~ehazan">Elad
                      Hazan</a>, <a href="http://cs.princeton.edu/">Cyril Zhang</a>, <a href="http://www.cs.princeton.edu/~yz7/">Yi Zhang</a> <br>
                    <em>International Conference on Machine Learning (ICML)</em>, 2019 <br>
                    <a href="http://proceedings.mlr.press/v97/agarwal19b/agarwal19b.pdf">pdf</a>
                    |
                    <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/docs/ggt/cite.bib">bibtex</a>
                    |
                    <a href="https://arxiv.org/abs/1806.02958">arXiv</a>
                  </p>
                  <p></p>
                  <p>Adaptive regularization methods come in diagonal and full-matrix variants. However, only the
                    former have enjoyed widespread adoption in training large-scale deep models. In this paper, we
                    show how to make full-matrix adaptive regularization practical and useful. At the heart of our
                    algorithm is an efficient method for computing the inverse square root of a low-rank matrix. We
                    show that GGT converges to first-order local minima, providing the first rigorous theoretical
                    analysis of adaptive regularization in non-convex optimization.</p>
                </td>
              </tr>
              <tr>
                <td width="25%" valign="middle">
                  <img width="220" src="./Karan Singh_files/lds-new.png">
                </td>
                <td width="75%" valign="top">
                  <p><a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/index.html#" name="lds-news">
                      <papertitle>Spectral Filtering for General Linear Dynamical Systems</papertitle>
                    </a><br>
                    with <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>, <a href="http://holdenlee.github.io/">Holden Lee</a>, <a href="http://cs.princeton.edu/">Cyril
                      Zhang</a>, <a href="http://www.cs.princeton.edu/~yz7/">Yi Zhang</a> <br>
                    <em>Neural Information Processing Systems (NIPS)</em>, 2018 <strong>Oral Presentation</strong><br>
                    <a href="https://papers.nips.cc/paper/7714-spectral-filtering-for-general-linear-dynamical-systems.pdf">pdf</a>
                    | <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/docs/lds-new/cite.bib">bibtex</a> | <a href="https://arxiv.org/abs/1802.03981">arXiv</a>
                  </p>
                  <p></p>
                  <p>We give a polynomial-time algorithm for learning latent-state linear dynamical systems without
                    system identification, and without assumptions on the spectral radius of the system's transition
                    matrix. The algorithm extends the recently introduced technique of spectral filtering, previously
                    applied only to systems with a symmetric transition matrix, using a novel convex relaxation to
                    allow for the efficient identification of phases.</p>
                </td>
              </tr>
              <tr><td width="25%" valign="middle">
                <img width="220" src="./Karan Singh_files/cartpole.jpg">
              </td>
              <td width="75%" valign="top">
                <p><a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/index.html#" name="lds-rl">
                    <papertitle>Towards Provable Control for Unknown Linear Dynamical Systems</papertitle>
                  </a><br>
                  with Sanjeev Arora, <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>, Holden Lee, Cyril
                  Zhang, <a href="http://www.cs.princeton.edu/~yz7/">Yi Zhang</a> <br>
                  <em>International Conference on Learning Representatios (ICLR)</em>, 2018 Workshop Track<br>
                  <a href="https://openreview.net/pdf?id=BygpQlbA-">pdf</a>
                  |
                  <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/docs/lqr-rl/cite.bib">bibtex</a>
                </p>
                <p></p>
                <p>We study the control of symmetric linear dynamical systems with unknown dynamics and a hidden
                  state. Using a recent spectral filtering technique, we formulate optimal control in this setting as
                  a convex program. This approach eliminates the need to solve the nonconvex problem of explicit
                  identification of the system and its latent state, and allows for provable optimality guarantees for
                  the control signal.</p>
              </td>
      </tr>
      <tr>
        <td width="25%" valign="middle">
          <img width="220" src="./Karan Singh_files/lds.png">
        </td>
        <td width="75%" valign="top">
          <p><a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/index.html#" name="lds-lr">
              <papertitle>Learning Linear Dynamical Systems
                via Spectral Filtering</papertitle>
            </a><br>
            with <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>, <a href="http://cs.princeton.edu/">Cyril
              Zhang</a> <br>
            <em>Neural Information Processing Systems (NIPS)</em>, 2017 <strong>Spotlight</strong><br>
            <a href="https://papers.nips.cc/paper/7247-learning-linear-dynamical-systems-via-spectral-filtering.pdf">pdf</a>
            |
            <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/docs/lds-old/cite.bib">bibtex</a>
            |
            <a href="https://arxiv.org/abs/1711.00946">arXiv</a>
          </p>
          <p></p>
          <p>We present an efficient and practical algorithm for the online prediction of discrete-time linear dynamical
            systems. Despite the non-convex optimization problem, our algorithm comes with provable guarantees: it has
            near-optimal regret bounds compared to the best LDS in hindsight, while overparameterizing the model by a
            small logarithmic factor. Our analysis brings together ideas from improper learning through convex
            relaxations, online regret minimization, and the spectral theory of Hankel matrices.</p>
        </td>
      </tr>
      <tr>
        <td width="25%" valign="middle">
          <img width="220" height="120" src="./Karan Singh_files/dp-price.png">
        </td>
        <td width="75%" valign="top">
          <p><a href="http://proceedings.mlr.press/v70/agarwal17a/agarwal17a.pdf" name="dp-price">
              <papertitle>The Price of Differential Privacy for Online Learning</papertitle>
            </a><br>
            with <a href="http://cs.princeton.edu/~namana/">Naman Agarwal</a><br>
            <em>International Conference on Machine Learning (ICML)</em>, 2017 <br>
            <a href="http://proceedings.mlr.press/v70/agarwal17a/agarwal17a.pdf">pdf</a>
            |
            <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/docs/dp-price/cite.bib">bibtex</a>
            |
            <a href="https://arxiv.org/abs/1701.07953">arXiv</a>
          </p>
          <p></p>
          <p>We design differentially private algorithms for the problem of online linear optimization in the full
            information and bandit settings with optimal $O(\sqrt{T})$
            regret bounds. In the full-information setting, our results demonstrate that $\epsilon$-differential privacy
            may be ensured for free. In particular, the regret bounds scale as $O\left(\sqrt{T}+{\epsilon}^{-1}\right)$.
            In the bandit setting, this is the first $O\left({\epsilon}^{-1}\sqrt{T}\right)$-regret algorithm.</p>
        </td>
      </tr>

      <tr>
        <td width="25%">
          <img width="220" src="./Karan Singh_files/onco-regret.png">
        </td>
        <td width="75%" valign="top">
          <p><a href="http://proceedings.mlr.press/v70/hazan17a/hazan17a.pdf" name="onco-regret">
              <papertitle>Efficient Regret Minimization in Non-Convex Games</papertitle>
            </a><br>
            with <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>, <a href="http://cs.princeton.edu/">Cyril
              Zhang</a> <br>
            <em>International Conference on Machine Learning (ICML)</em>, 2017 <br>
            <a href="http://proceedings.mlr.press/v70/hazan17a/hazan17a.pdf">pdf</a>
            |
            <a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/docs/onco-regret/cite.bib">bibtex</a> |
            <a href"https:="" arxiv.org="" abs="" 1708.00075"="">arXiv</a>
          </p>
          <p></p>
          <p>We consider regret minimization in repeated games with non-convex loss functions. Minimizing the standard
            notion of regret is computationally intractable. Thus, we define a natural notion of regret which permits
            efficient optimization and generalizes offline guarantees for convergence to an approximate local optimum.
            We give gradient-based methods that achieve optimal regret, which in turn guarantee convergence to
            equilibrium in this framework.</p>
        </td>
      </tr>

      <tr>
        <td width="25%">
          <img width="220" src="./Karan Singh_files/ds-vae.png">
        </td>
        <td width="75%" valign="top">
          <p><a href="file://wsl.localhost/Arch/home/karan/i-am-karan-singh.github.io/index.html#">
              <papertitle>Dynamic Task Allocation for Crowdsourcing
            </papertitle></a><br>
            with <a href="http://www.pacm.princeton.edu/node/368">Irineo Cabreros</a>, <a href="http://www.orie.cornell.edu/people/students_phd.cfm?grad=2362&amp;year=2017">Angela Zhou</a> <br>
            Prelim at <em>ICML Workshop on Data Efficient Machine Learning</em>, 2016<br>
        </p></td>
      </tr>
    </tbody>
  </table>
  <table cellspacing="0" cellpadding="20" border="0" width="100%" align="center">
    <tbody>
      <tr>
        <td>
          <heading>Teaching</heading> (Assistantships in Instruction)
        </td>
      </tr>
    </tbody>
  </table>
  <table cellpadding="7" border="0" width="100%" align="center">
    <tbody>
      <tr>
        <td width="25%"><img src="./Karan Singh_files/teach.png" width="220" height="160"></td>
        <td width="75%" valign="center">
          <p>
            <a href="http://www.cs.princeton.edu/courses/archive/fall16/cos402/">
              <papertitle>COS 402: Machine Learning and Artificial Intelligence</papertitle>
            </a><br>
            <em>Princeton University</em>, Fall 2016<br>
            <strong>Instructors</strong>: Prof. <a href="http://cs.princeton.edu/~arora/">Sanjeev Arora</a>, Prof. <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a><br>
          </p>
          <p>
            <a href="http://www.cs.princeton.edu/courses/archive/fall17/cos324/">
              <papertitle>COS 324: Introduction to Machine Learning</papertitle>
            </a><br>
            <em>Princeton University</em>, Fall 2017<br>
            <strong>Instructors</strong>: Prof. <a href="http://cs.princeton.edu/~ehazan">Elad Hazan</a>, Prof. <a href="http://cs.princeton.edu/~ysinger">Yoram Singer</a>
            <br>
          </p>
        </td>
      </tr>
    </tbody>
  </table>


</td></tr></tbody></table></body></html>